In the project i have explored the following classes and functions:
1. tokenizer.fit_on_texts([]) >> It is take the input of a multiple string in list format and gives and provides token for each word like:
(the': 1,'you': 2,'i': 2,'to': 4,'a': 5,'of': 6,'is': 7,)
2. tokenizer.texts_to_sequences([sentence]). This function done a wonderful job:
3. [[93, 1, 13]] is the sequence os the text "About the program" ####Wonderful
4. 
